{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d536c-4390-4372-8c80-b30d39fd2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3c317-d53f-4cc9-923e-d196412935a0",
   "metadata": {},
   "source": [
    "### Step 1: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727a63f-90c3-42f3-86cf-bd0fe07e6e68",
   "metadata": {},
   "source": [
    "#### 1.1 Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfd133-ca29-492e-b27c-7977177492f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"../data/raw/train.csv\")\n",
    "test_df=pd.read_csv(\"../data/raw/test.csv\")\n",
    "sample_sumbission=pd.read_csv(\"../data/raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a35dc-dd99-4756-aac8-815671ba06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a7447-1a0e-4c0c-bad5-111bf4bbeff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a1017-71bd-4a78-aedb-c16f68c6c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0b811-9ff5-4642-81ba-379d4c892bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fafb46-3347-4b1a-8446-1ac2aaeb8c88",
   "metadata": {},
   "source": [
    "#### 1.2 Perform Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fc3e5-1b35-4f6e-9183-e0d054b43fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rows (data points) and columns (features) exist.\n",
    "print(\"Train Shape\", train_df.shape)\n",
    "print(\"Test Shape\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de546fc0-42be-4804-baa7-9ec45ff2bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values\n",
    "missing_values=train_df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcb724-5eae-4574-900b-34033a4ace07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand distributions of numerical and categorical features.\n",
    "numerical_cols=train_df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "categorical_cols=train_df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_cols.remove(\"Premium Amount\")\n",
    "print(\"Numerical Features\",numerical_cols)\n",
    "print(\"Categorical Features\",categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d8150-3863-4e85-9b0a-7f9c4e6a0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data visualizations to find relationships between features.\n",
    "# Distributions of Numerical Features\n",
    "train_df[numerical_cols].hist(figsize=(15,10),bins=30)\n",
    "plt.suptitle(\"Distribution of Numerical Features\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce493881-8cf4-43bc-82af-7e5f55d0fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Categorical Features\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    top_categories=train_df[col].value_counts().nlargest(10).index # Top 10 categories\n",
    "    sns.countplot(x=col, data=train_df[train_df[col].isin(top_categories)])\n",
    "    plt.title(f\"Top 10 Distribution of {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c6614-ad4b-415a-8eb5-a8471b7e0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable Distribution \n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(train_df[\"Premium Amount\"],bins=50,kde=True)\n",
    "plt.title(\"Distribution of Insurance Premium\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75388e3-171b-494e-ab80-996a6fabe88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(\n",
    "    train_df[numerical_cols].corr(),\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 12,\"rotation\": 45},  # make text readable\n",
    "    square=True\n",
    ")\n",
    "\n",
    "plt.title(\"Correlation Heatmap\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88fb68-a816-42ce-8f73-5b0cb0ce3736",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7846e-d519-48ea-b05d-3c4fb5382449",
   "metadata": {},
   "source": [
    "#### 2.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870165b-fdad-4c3a-90fa-7e2cc456f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numerical missing values\n",
    "for col in numerical_cols:\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col].fillna(median_val, inplace=True)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ef487-4ae1-4f3e-94e6-0c1e220898a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill categorical missing values\n",
    "for col in categorical_cols:\n",
    "    mode_val = train_df[col].mode()[0]\n",
    "    train_df[col].fillna(mode_val, inplace=True)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col].fillna(mode_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10703e67-f1f4-4997-b0c9-e6dd0ab71653",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values after imputation:\\n\", train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e49835-3b13-4bc8-a8ce-a6a31bf62ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to fix data types\n",
    "# Numeric\n",
    "for col in numerical_cols:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "\n",
    "# Dates\n",
    "if 'Policy Start Date' in train_df.columns:\n",
    "    train_df['Policy Start Date'] = pd.to_datetime(train_df['Policy Start Date'], errors='coerce')\n",
    "    test_df['Policy Start Date'] = pd.to_datetime(test_df['Policy Start Date'], errors='coerce')\n",
    "\n",
    "# Categorical\n",
    "for col in categorical_cols:\n",
    "    if col in train_df.columns and col != 'Policy Start Date':\n",
    "        train_df[col] = train_df[col].astype('object')\n",
    "    if col in test_df.columns and col != 'Policy Start Date':\n",
    "        test_df[col] = test_df[col].astype('object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba6085-df5f-439a-adab-dc05bbda20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle skewed numerical features\n",
    "skewed_cols = ['Annual Income', 'Health Score']\n",
    "for col in skewed_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = np.log1p(train_df[col])\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = np.log1p(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5109944-2f5f-4a44-9014-c0ca3c7ef93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train_df['Previous Claims'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdf43c-9902-4aed-9767-0cd145852674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers in Previous Claims using IQR method\n",
    "if 'Previous Claims' in train_df.columns:\n",
    "    Q1 = train_df['Previous Claims'].quantile(0.25)\n",
    "    Q3 = train_df['Previous Claims'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    train_df['Previous Claims'] = train_df['Previous Claims'].clip(lower, upper)\n",
    "    if 'Previous Claims' in test_df.columns:\n",
    "        test_df['Previous Claims'] = test_df['Previous Claims'].clip(lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d52832-1656-46cc-ab1e-60a9ad16ba7c",
   "metadata": {},
   "source": [
    "#### 2.2 Convert Categorical Variables to Numerical Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66a0e8-ba5f-4039-b7c4-d63c1432fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary categorical columns (Label Encoding)\n",
    "binary_cols = ['Gender', 'Smoking Status']\n",
    "le = LabelEncoder()\n",
    "for col in binary_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = le.fit_transform(train_df[col])\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = le.transform(test_df[col])\n",
    "\n",
    "# Ordinal columns \n",
    "education_order = {\"High School\":1, \"Bachelor's\":2, \"Master's\":3, \"PhD\":4}\n",
    "exercise_order = {\"Rarely\":1, \"Monthly\":2, \"Weekly\":3, \"Daily\":4}\n",
    "\n",
    "if 'Education Level' in train_df.columns:\n",
    "    train_df['Education Level'] = train_df['Education Level'].map(education_order)\n",
    "    test_df['Education Level'] = test_df['Education Level'].map(education_order)\n",
    "if 'Exercise Frequency' in train_df.columns:\n",
    "    train_df['Exercise Frequency'] = train_df['Exercise Frequency'].map(exercise_order)\n",
    "    test_df['Exercise Frequency'] = test_df['Exercise Frequency'].map(exercise_order)\n",
    "\n",
    "# Multi-class categorical columns (One-Hot Encoding)\n",
    "multi_cols = ['Marital Status', 'Occupation', 'Location', 'Property Type', 'Policy Type']\n",
    "train_df = pd.get_dummies(train_df, columns=[col for col in multi_cols if col in train_df.columns], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=[col for col in multi_cols if col in test_df.columns], drop_first=True)\n",
    "\n",
    "\n",
    "# Align train and test columns\n",
    "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "for col in ['Policy Start Date', 'Customer Feedback']:\n",
    "    if col in train_df.columns:\n",
    "        train_df.drop(columns=[col], inplace=True)\n",
    "    if col in test_df.columns:\n",
    "        test_df.drop(columns=[col], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453fa45-108a-4f08-bf60-29238e18695d",
   "metadata": {},
   "source": [
    "#### 2.3  Split the Data into Training and Evaluation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d690fc0-e632-4352-b387-9b94e1dd3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = train_df.drop(columns=['Premium Amount'])\n",
    "y = train_df['Premium Amount']\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Evaluation set:\", X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f905d-8799-473e-ab6f-7d7ee5d8d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle any remaining missing values in X_train/X_eval\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().sum() > 0:\n",
    "        if X_train[col].dtype in ['float64','int64']:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col].fillna(median_val, inplace=True)\n",
    "            X_eval[col].fillna(median_val, inplace=True)\n",
    "        else:\n",
    "            mode_val = X_train[col].mode()[0]\n",
    "            X_train[col].fillna(mode_val, inplace=True)\n",
    "            X_eval[col].fillna(mode_val, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f923922-1962-48d1-a684-71638b5853fb",
   "metadata": {},
   "source": [
    "#### 2.4  Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ec69c-cc83-45b9-bea1-2707c5ea0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns to scale (excluding target)\n",
    "num_cols = ['Age','Annual Income','Number of Dependents','Health Score',\n",
    "            'Previous Claims','Vehicle Age','Credit Score','Insurance Duration']\n",
    "num_cols = [col for col in num_cols if col in X_train.columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_eval[num_cols] = scaler.transform(X_eval[num_cols])\n",
    "test_num_cols = [col for col in num_cols if col in test_df.columns]\n",
    "test_df[test_num_cols] = scaler.transform(test_df[test_num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb463476-eb05-4033-93fb-7f5e946a6704",
   "metadata": {},
   "source": [
    "### Step 3: Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031b849-d63f-4d3b-8709-0b747646ba12",
   "metadata": {},
   "source": [
    "### 3.1 Choose Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164eb47-904d-4ca1-b5a0-5c67b91e6f26",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45806193-00c6-4c2c-b458-9ea558daf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_eval)\n",
    "results.append(evaluate_model(y_eval, y_pred_lr, \"Linear Regression\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81d17b-d1d1-412f-bd3c-cd12d3c22cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Linear Regression\"):\n",
    "    y_true_clipped = np.maximum(y_true, 0)\n",
    "    y_pred_clipped = np.maximum(y_pred, 0)\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "        \"RMSLE\": np.sqrt(mean_squared_log_error(y_true_clipped, y_pred_clipped)),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22f05f-4c34-4114-a87d-4fc2be37c17c",
   "metadata": {},
   "source": [
    "##### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d48ae-3e23-4bb2-b220-f8c907becc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_eval)\n",
    "results.append(evaluate_model(y_eval, y_pred_dt, \"Decision Tree\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118db311-ff2d-45c2-b421-4c9fec952649",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a92c7-3404-482d-9851-4b13b49db75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50,       # Reduce number of trees\n",
    "    max_depth=10,          # Limit depth of trees\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_eval)\n",
    "results.append(evaluate_model(y_eval, y_pred_rf, \"Random Forest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fdefc-bfe8-47ff-87d9-df44c860f402",
   "metadata": {},
   "source": [
    "##### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a3c0b-42f3-4017-a547-da9bb97725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,        # Reduce if still slow\n",
    "    max_depth=6,             # Limit depth\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,           # Use 80% of data for each tree\n",
    "    colsample_bytree=0.8,    # Use 80% of features per tree\n",
    "    tree_method='hist',      # Faster for large datasets\n",
    "    n_jobs=-1,               # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_eval)\n",
    "results.append(evaluate_model(y_eval, y_pred_xgb, \"XGBoost\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff14a7-1f09-440a-bf59-ff671b36669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert results to DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"RMSE\")  # Sort by RMSE\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790a571-c595-4d95-8cbd-52c4ae597c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-performing model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\nBest-performing model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246dbf6-f3d9-4d2a-ba7f-1bb69fe88ff0",
   "metadata": {},
   "source": [
    "### Step 4: ML Pipeline & MLflow Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef3101-a66e-4cc2-9b70-0737e52b3096",
   "metadata": {},
   "source": [
    "#### 4.1 Build an ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dab1d2-8553-4a06-bdfa-fa5f52bbf008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a8474-c0b2-42a7-8dd2-2f894f0b6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8b1e9-ac7e-43f1-bd75-63d98c512301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    y_true_clipped = np.clip(y_true, 0, None)\n",
    "    y_pred_clipped = np.clip(y_pred, 0, None)\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "        \"RMSLE\": np.sqrt(mean_squared_log_error(y_true_clipped, y_pred_clipped)),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037e331-49dd-491c-aacc-238309deb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split features and target \n",
    "X = train_df.drop(\"Premium Amount\", axis=1)\n",
    "y = train_df[\"Premium Amount\"]\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a4bc6-ca7c-48de-8e6c-2ebf97fd7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical & categorical columns\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0745ac7-8809-4d7d-9d83-aadc453f0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, numerical_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d4a42-31be-426e-848d-fd78ab72050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=50, max_depth=5, n_jobs=-1, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=50, max_depth=3, n_jobs=-1, random_state=42, verbosity=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121dac1-f66a-422f-9541-55eeee19d22e",
   "metadata": {},
   "source": [
    "#### 4.2 Track Experiments with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67a562-9b33-47db-b1d4-76d3a16f5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models, evaluate, and log in MLflow\n",
    "pipeline_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Train model\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_eval)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(y_eval, y_pred)\n",
    "        pipeline_results.append({\"Model\": name, **metrics})\n",
    "        \n",
    "        # Log parameters\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            mlflow.log_params(model.get_params())\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model tag\n",
    "        mlflow.set_tag(\"Model\", name)\n",
    "        \n",
    "        # Signature and input example\n",
    "        X_input_example = X_eval.iloc[:5]\n",
    "        signature = infer_signature(X_input_example, pipe.predict(X_input_example))\n",
    "        \n",
    "        # Log pipeline\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipe,\n",
    "            name=name.replace(\" \", \"_\") + \"_pipeline\",\n",
    "            signature=signature,\n",
    "            input_example=X_input_example\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fb933-f385-4959-a51b-04078cf02a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "pipeline_results_df = pd.DataFrame(pipeline_results).sort_values(by=\"RMSE\")\n",
    "print(\"\\nEvaluation metrics for all models:\")\n",
    "print(pipeline_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2aedbb-b49b-4a01-bf60-f08103559739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best pipeline\n",
    "best_model_name = pipeline_results_df.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest model selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "best_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(best_pipe, \"best_model.pkl\")\n",
    "print(\"\\nâœ… Best model pipeline saved as best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a4524-cc62-498b-98ac-bd1adc087bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
